<!DOCTYPE html>
<!--[if IE 8]> 
<html lang="en" class="ie8">
   <![endif]-->
   <!--[if IE 9]> 
   <html lang="en" class="ie9">
      <![endif]-->
      <!--[if !IE]><!--> 
      <html lang="en">
         <!--<![endif]-->
         <head>
            <title>Guochen Yu</title>
            <!-- Meta -->
            <meta charset="utf-8">
            <meta http-equiv="X-UA-Compatible" content="IE=edge,Chrome=1">
            <!-- <meta name="viewport" content="width=device-width, initial-scale=1.0">-->
            <meta name="description" content="Guochen Yu's homepage">
            <link rel="shortcut icon" href="assets/images/log.png">
            <link href='https://fonts.googleapis.com/css?family=Roboto:400,500,400italic,300italic,300,500italic,700,700italic,900,900italic' rel='stylesheet' type='text/css'>
            <!-- Global CSS -->
            <link rel="stylesheet" href="assets/css/bootstrap.min.css">
            <link rel="stylesheet" href="assets/css/font-awesome/css/font-awesome.min.css">
            <link rel="stylesheet" href="assets/css/main.css">
            <script src="bootstrap/js/bootstrap.min.js"></script>
            <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
            <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
            <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
            <![endif]-->
            <script>
               (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
               (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
               m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
               })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
               
               ga('create', 'UA-88572407-1', 'auto');
               ga('send', 'pageview');
            </script>
         </head>
         <body>
            <div class="container">
            <div class="row">
               <div class='row'>
                  <hr>
                  <div class='col-xs-5'>
                     <hr>
                     <div class='photo'>
                        <img src="assets/images/cv.jpg" alt="photo"/>
                     </div>
                  </div>
                  <div class='col-xs-6'>
                     <h3>
                        Guochen Yu 余果宸
                     </h3>
                     <p>
					 <p>
					 <p>
                  I am currently a Ph.D. student in Communication University of China and also a joint PhD. studentat Institute of Acoustics, Chinese Academy of Sciences (IACAS) supervised by <a href="http://people.ucas.ac.cn/~cszheng">Prof.Chengshi Zheng</a> and <a href="http://ices.cuc.edu.cn/2019/0918/c5332a135655/page.htm">Prof.Hui Wang</a>. Before that, I received my bachelor's degree from the school of information and communication engineering at Communication University of China in 2017.
                     </p>
                     <h3 style="padding-top:-1px"></h3>
                     <a href="mailto: yuguochen@cuc.edu.cn"><i class="fa fa-envelope"></i> &nbsp; yuguochen@cuc.edu.cn</a>
                     &nbsp; &nbsp; &nbsp;
                     <a href="https://github.com/yuguochencuc" target="_blank"><i class="fa fa-github-square"></i> &nbsp; Github</a>
                     &nbsp; &nbsp; &nbsp;
                     <a href="https://scholar.google.com/citations?hl=en&user=BeYoFhMAAAAJ" target="_blank"><i class="fa fa-globe"></i> &nbsp; Google Scholar</a>
                  </div>
               </div>
               <hr>
               <div class='researchInt'>
                  <h3 style="padding-top:-5px">Research Interest</h3>
                  <p>My research interests include the front-end techniques for speech and audio and music generation, such as monaural supervised speech enhancement, unsupervised speech enhancment, and audio packet loss concealment .</p>
                  </div>
                  <hr>
               <h3>
                  <a name='publications'></a> Publications
               </h3>
               
               <h4>
                  <a name='2022'></a> 2022
             </h4>

             <div class="media">
               <div class="media-body">
                  <p class="media-heading">
                     <strong>Joint Magnitude Estimation and Phase Recovery Using Cycle-in-Cycle GAN for Non-Parallel Speech Enhancement</strong><br />
                     <strong>Guochen Yu</strong>, Andong Li, Yutian Wang, Chengshi Zheng, Hui Wang, Qin Zhang<br />
                     <a href="https:"></a> in IEEE International Conference on Acoustics, Speech, & Signal Processing (<strong>ICASSP2022</strong>)<br/>
                  </p>
               </div>
            </div>

             <div class="media">
               <div class="media-body">
                  <p class="media-heading">
                     <strong>Dual-Branch Attention-in-Attention Transformer for Speech Enhancement</strong><br />
                     <strong>Guochen Yu</strong>, Andong Li, Yinuo Guo, Yutian Wang, Chengshi Zheng, Hui Wang<br />
                     <a href="https:"></a> in IEEE International Conference on Acoustics, Speech, & Signal Processing (<strong>ICASSP2022</strong>)<br/>
                  </p>
               </div>
            </div>
            
	       <div class="media">
		  <div class="media-body">
		     <p class="media-heading">
			<strong>DBT-Net: Dual-branch federative magnitude and phase estimation with attention-in-attention transformer for monaural speech enhancement</strong><br />
			<strong>Guochen Yu</strong>,Andong Li, Hui Wang, Yutian Wang, Yuxuan Ke, Chengshi Zheng<br />
			<a href="https:"></a> Submitted to IEEE/ACM Transactions on Audio, Speech, and Language Processing (<strong>IEEE/ACM TASLP</strong>) <br />
		     </p>
		  </div>
	       </div>		    

             <div class="media">
               <div class="media-body">
                  <p class="media-heading">
                     <strong>DMF-Net: A decoupling-style multi-band fusion model for real-time full-band speech enhancement</strong><br />
                     <strong>Guochen Yu</strong>, Yuansheng Guan, Weixin Meng, Chengshi Zheng, Hui Wang<br />
                     <a href="https:"></a> Submitted to European Signal Processing Conference (<strong>EUSIPCO2021</strong>)<br/>
                  </p>
               </div>
            </div>

             <div class="media">
               <div class="media-body">
                  <p class="media-heading">
                     <strong>Optimizing Shoulder to Shoulder: A Coordinated Sub-Band Fusion Model for Real-Time Full-Band Speech Enhancement</strong><br />
                     <strong>Guochen Yu</strong>, Yuansheng Guan, Weixin Meng, Chengshi Zheng, Hui Wang<br />
                     <a href="https:"></a> Submitted to Annual Conference of the International Speech Communication Association (<strong>Interspeech2021</strong>)<br/>
                  </p>
               </div>
            </div>
		    
			   <h4>
                    <a name='2021'></a> 2021
               </h4>
               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>MT-in-MS: Incorporating multi-target in an efficient multi-stage speech enhancement model for better generalization</strong><br />
                        Lu Zhang, Mingjiang Wang, <strong> Andong Li</strong>, Xuyi Zhuang, Zehua Zhang<br />
                        <a href="https:"></a> in Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (<strong>APSIPA2021</strong>)<br />
                     </p>
                  </div>
               </div> 

               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Deep Learning-based Stereophonic Acoustic Echo Suppression without Decorrelation</strong><br />
                        Linjuan Cheng, Renhua Peng, <strong>Andong Li</strong>, Chengshi Zheng, Xiaodong Li<br />
                        <a href="https:"></a> Journal of the Acoustical Society of America (<strong>JASA</strong>)<br />
                     </p>
                  </div>
               </div>


               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>A Simultaneous Denoising and Dereverberation Framework with Target Decoupling</strong><br />
                        <strong> Andong Li</strong>, Wenzhe Liu, Xiaoxue Luo, Guochen Yu, Chengshi Zheng, Xiaodong Li<br />
                        in Annual Conference of the International Speech Communication Association (<strong>Interspeech2021</strong>)<br />
                        <a href="https:"></a>
                     </p>
                  </div>
               </div>

               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Know Your Enemy, Know Yourself: A Unified Two-Stage Framework for Speech Enhancement</strong><br />
                        Wenzhe Liu, <strong> Andong Li</strong>, Yuxuan Ke, Chengshi Zheng, Xiaodong Li<br />
                        in Annual Conference of the International Speech Communication Association (<strong>Interspeech2021</strong>)<br />
                        <a href="https:"></a>
                     </p>
                  </div>
               </div> 

               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Two Heads Are Better than One: A Two-Stage Complex Spectral Mapping Approach for Monaural Speech Enhancement</strong><br />
                        <strong>Andong Li</strong>, Wenzhe Liu, Chengshi Zheng, Cunhang Fan, Xiaodong Li<br />
                        <a href="https:"></a> IEEE/ACM Transactions on Audio, Speech, and Language Processing (<strong>IEEE/ACM TASLP</strong>)
                     </p>
                  </div>
               </div> 

               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Learning to Inference with Early Exit in the Progressive Speech Enhancement</strong><br />
                        <strong>Andong Li</strong>, Chengshi Zheng, Lu Zhang, Xiaodong Li<br />
                        <a href="https:"></a>in European Signal Processing Conference (<strong>EUSIPCO2021</strong>)<br />
                     </p>
                  </div>
               </div> 

               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>ICASSP 2021 Deep Noise Suppression Challenge: Decoupling Magnitude and Phase Optimization with A Two-Stage Deep Network</strong><br />
                        <strong>Andong Li</strong>, Wenzhe Liu, Xiaoxue Luo, Chengshi Zheng, Xiaodong Li<br />
                        <a href="https://"></a>in IEEE International Conference on Acoustics, Speech, & Signal Processing (<strong>ICASSP2021</strong>)<br/>
                     </p>
                  </div>
               </div>  

               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Low-Complexity Artificial Noise Suppression Methods for Deep Learning-based Speech Enhancement Algorithms</strong><br />
                        Yuxuan Ke, <strong>Andong Li</strong>, Chengshi Zheng, Renhua Peng, Xiaodong Li<br />
                        <a href="https://"></a> EURASIP Journal on Audio, Speech, and Music Processing, 2021<br/>
                     </p>
                  </div>
               </div>

               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>On the importance of power compression and phase estimation in monaural speech dereveberation</strong><br />
                        <strong>Andong Li</strong>, Chengshi Zheng, Renhua Peng, Xiaodong Li<br />
                        <a href="https://"></a> Journal of the Acoustical Society of America, Express Letters (<strong>JASA EL</strong>), 2021<br/>
                     </p>
                  </div>
               </div>

               <h4>
                  <a name='2020'></a> 2020
             </h4>

               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>A Recursive Network with Dynamic Attention for Monaural Speech Enhancement</strong><br />
                        <strong>Andong Li</strong>, Chengshi Zheng, Cunhang Fan, Renhua Peng, Xiaodong Li<br />
                        in Annual Conference of the International Speech Communication Association (<strong>Interspeech2020</strong>)<br />
                     <a href="https://www.isca-speech.org/archive/Interspeech_2020/abstracts/1513.html">[Link]</a>
                     </p>
                  </div>
               </div>
               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>A Time-domain Monaural Speech Enhancement with Feedback Learning</strong><br />
                        <strong>Andong Li</strong>, Chengshi Zheng, Linjuan Cheng, Renhua Peng, Xiaodong Li<br />
                        in Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (<strong>APSIPA2020</strong>)<br />
                     <a href="https://arxiv.org/abs/2003.09815">[Link]</a>
                     </p>
                  </div>
               </div>
               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Speech enhancement using progressive learning-based convolutional recurrent neural network</strong><br />
                        <strong>Andong Li</strong>, Mingmin Yuan, Chengshi Zheng, Xiaodong Li<br />
                        in Applied Acoustics (<strong>AA</strong>), 2020<br />
                     <a href="https://www.sciencedirect.com/science/article/pii/S0003682X19309326?casa_token=_egeo9yGOVEAAAAA:WMEqYO56Tv61gyfSsYhx5zenVnBpGR8kzBlazekDg_ME0Ax8xQtEq8A7wWLUxQ0yNx4YQoI4mwpE">[Link]</a>
                     </p>
                  </div>
               </div>
			   <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>A Supervised Speech Enhancement Approach with Residual Noise Control for Voice Communication</strong><br />
                        <strong>Andong Li</strong>, Renhua Peng, Chengshi Zheng, Xiaodong Li<br />
                        in Applied Sciences(<strong>AS</strong>), 2020<br />
                     <a href="https://www.mdpi.com/search?q=A+Supervised+Speech+Enhancement+Approach+with+Residual+Noise+Control+for+Voice+Communication&authors=&journal=&article_type=&search=Search&section=&special_issue=&volume=&issue=&number=&page=">[Link]</a>
                     </p>
                  </div>
               </div>

               <h3>
                  <a name='manuscripts'></a> Manuscripts
               </h3>

               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>TaylorBeamformer: Learning All-Neural Multi-Channel Speech Enhancement from Taylor's Approximation Theory</strong><br />
                        <strong>Andong Li</strong>, Guochen Yu, Chengshi Zheng, Xiaodong Li<br />
                        <a href="https:"></a> Submitted to Interspeech2022<br />
                     </p>
                  </div>
               </div>

               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>MDNet: Learning Monaural Speech Enhancement from Deep Prior Gradient</strong><br />
                        <strong>Andong Li</strong>, Chengshi Zheng, Ziyang Zhang, Xiaodong Li<br />
                        <a href="https:"></a> Submitted to Interspeech2022<br />
                     </p>
                  </div>
               </div>

               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>DBT-Net: Dual-branch federative magnitude and phase estimation with attention-in-attention transformer for monaural speech enhancement</strong><br />
                        Guochen Yu, <strong>Andong Li</strong>, Hui Wang, Yutian Wang, Yuxuan Ke, Chengshi Zheng<br />
                        <a href="https:"></a> Submitted to IEEE/ACM Transactions on Audio, Speech, and Language Processing (<strong>IEEE/ACM TASLP</strong>) <br />
                     </p>
                  </div>
               </div>

               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Low-latency monaural speech enhancement with deep filter-bank equalizer</strong><br />
                        Chengshi Zheng, Wenzhe Liu, <strong> Andong Li</strong>, Xiaodong Li<br />
                        <a href="https:"></a> Submitted to Journal of the Acoustical Society of America (<strong>JASA</strong>)<br />
                     </p>
                  </div>
               </div>

               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Learning to Glance and Gaze for Speech Enhancement With a Collaborative-Style Framework</strong><br />
                        <strong> Andong Li</strong>, Guochen Yu, Chengshi Zheng, Xiaodong Li<br />
                        <a href="https:"></a> Submitted to IEEE/ACM Transactions on Audio, Speech, and Language Processing (<strong>IEEE/ACM TASLP</strong>) <br />
                     </p>
                  </div>
               </div>



               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Two Heads Are Better than One: A Two-Stage Approach for Monaural Noise Reduction in the Complex Domain</strong><br />
                        <strong>Andong Li</strong>, Chengshi Zheng, Renhua Peng, Xiaodong Li<br />
                        <a href="https://arxiv.org/abs/2011.01561">[Arxiv]</a>
                     </p>
                  </div>
               </div>  
               
               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>The IOA System for Deep Noise Suppression Challenge using a Framework Combining Dynamic Attention and Recursive Learning</strong><br />
                        <strong>Andong Li</strong>, Chengshi Zheng, Renhua Peng, Linjuan Cheng, Xiaodong Li</<br />
                        <a href="https://arxiv.org/abs/2005.05855">[Arxiv]</a> 
                     </p>
                  </div>
               </div>
               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Dynamic Attention Based Generative Adversarial Network with Phase Post-Processing for Speech Enhancement</strong><br />
                        <strong>Andong Li</strong>, Chengshi Zheng, Renhua Peng, Cunhang Fan, Xiaodong Li<br />
                        <a href="https://arxiv.org/abs/2006.07530">[Arxiv]</a> 
                     </p>
                  </div>
               </div>
               <hr>

               <h3>
                  <a name='academic-services'></a> Academic Services
               </h3>
               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Reviewer for Conferences:</strong><br />
                        ACM International Conference on Multimedia (<strong>ACMMM</strong>, 2021/2022)<br />
                        International Conference on Learning Representations (<strong>ICLR</strong>, 2021)<br />

                     </p>
                  </div>
               </div>

               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                        <strong>Reviewer for Journals:</strong><br />
                        IEEE Signal Processing Letters (<strong>SPL</strong>)<br/>
                        IEEE/ACM Transactions on Audio, Speech, and Language processing (<strong>TASLP</strong>)<br/>
                        Neural Networks (<strong>NN</strong>)<br/>
                        Pattern Recognition (<strong>PR</strong>)<br/>
                     </p>
                  </div>
               </div>


               <h3>
                  <a name='selected-awards'></a> Selected Awards
               </h3>
               <div class="media">
                  <div class="media-body">
                     <p class="media-heading">
                     [2021/03] Champion of Interspeech 2021 Deep Noise Suppression (DNS) Challenge in 1st track. Check the <a href="https://www.microsoft.com/en-us/research/academic-program/deep-noise-suppression-challenge-interspeech-2021/">website</a><br />
                     [2020/11] National scholarship<br />
                     [2020/10] Champion of ICASSP 2021 Deep Noise Suppression (DNS) Challenge in 1st track. Check the <a href="https://www.microsoft.com/en-us/research/dns-challenge/icassp2021/home">website</a><br />
                     [2020/10] Pacemaker to Merit Student, IACAS<br />
                     [2020/05] 8th of INTERSPEECH 2020 Deep Noise Suppression in the Real-time Track. Check the <a href="https://www.microsoft.com/en-us/research/dns-challenge/interspeech2020/home">website</a><br />
                     [2018/12] National Mathematical Modeling Contest for Postgraduates, Second Price<br />
                     [2016/06] National Encouragement scholarship, Southeast University<br />                        
                     </p>
                  </div>
               </div>
               <hr>               
            </div>
            </div>

            <!--//main-body-->
            <hr>
            <footer class="footer">
               <div class="container">
                  <small class="copyright"> 2022 Guochen Yu</small>
               </div>
               <!--//container-->
            <!--/footer-->
            <!--//footer-->
            <!--div style="display:inline-block;width:200px;">
               <script type="text/javascript" src="//rf.revolvermaps.com/0/0/8.js?i=5ekw1not1zt&amp;m=8&amp;c=ff0000&amp;cr1=ffffff&amp;f=arial&amp;l=0" async="async"></script>
            </div-->
         </body>
      </html>
